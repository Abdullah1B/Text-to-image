{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb8e7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from training_loop import training_loop\n",
    "\n",
    "\n",
    "trainer = training_loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2e605",
   "metadata": {},
   "source": [
    "### Trianing the GAN model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb7b7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/500] Batch 0/60                     Loss D: 3.1379, loss G: 63.0617, \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Project\\Text-to-image\\training_loop.py:55\u001b[0m, in \u001b[0;36mtraining_loop.train\u001b[1;34m(self, train_on_notebook)\u001b[0m\n\u001b[0;32m     51\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mEPOCHS):\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[0;32m     57\u001b[0m         real_image     \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_images\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mDEVICE)\n\u001b[0;32m     58\u001b[0m         text_embedding \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mDEVICE)\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\Desktop\\Project\\Text-to-image\\Text_image_dataset.py:83\u001b[0m, in \u001b[0;36mText_image_dataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     80\u001b[0m wrong_image \u001b[38;5;241m=\u001b[39m transform(wrong_image)\n\u001b[0;32m     81\u001b[0m wrong_image \u001b[38;5;241m=\u001b[39m (wrong_image \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m127.5\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m127.5\u001b[39m\n\u001b[1;32m---> 83\u001b[0m text_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m sample \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_images\u001b[39m\u001b[38;5;124m'\u001b[39m:right_image, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m           }\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "File \u001b[1;32m~\\Desktop\\Project\\Text-to-image\\Text_image_dataset.py:54\u001b[0m, in \u001b[0;36mText_image_dataset.get_text_embedding\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     51\u001b[0m segment_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([segment_ids])\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 54\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43msegment_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     57\u001b[0m token_vector \u001b[38;5;241m=\u001b[39m hidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1019\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1010\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1012\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1013\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1014\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1018\u001b[0m )\n\u001b[1;32m-> 1019\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1032\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:609\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    600\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    601\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    602\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    607\u001b[0m     )\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 609\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:425\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    417\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    424\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 425\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    435\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:307\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(hidden_states))\n\u001b[1;32m--> 307\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose_for_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n\u001b[0;32m    311\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\ajbas\\sklearn-venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:271\u001b[0m, in \u001b[0;36mBertSelfAttention.transpose_for_scores\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose_for_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    270\u001b[0m     new_x_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size)\n\u001b[1;32m--> 271\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_x_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a2601",
   "metadata": {},
   "source": [
    "### Predicate new sampels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f32e9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = trainer.generate('male')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e16bf",
   "metadata": {},
   "source": [
    "### Using a pre_trianed model\n",
    "\n",
    "if the generator output 128x128\n",
    "\n",
    "set `use_128` to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = trainer.generate(text = 'male',path_model = 'path/pre_trained',use_pre_train = True,use_128 = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
